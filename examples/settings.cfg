[MAIN]
seqlen = 256
vocab_size = 50257
emb_size = 768
hidden_sizes = [256, 512, 1024]
norm = True
dropout = 0.15
num_epochs = 10
batch_size = 64
lr = 1e-3
num_tokens = 256
arch_gru  = minGRU
arch_lstm = minLSTM
arch = minLSTM
optim = adamw
datasetA = tiny-shakespeare

[DS]
checkpoint_dir = "/home/shelbys/code/werernns/mingru/results/models"
load_checkpoint_dir = None
dtype = bf16
local_rank = -1

[DATA]
test  = "/home/shelbys/Datasets/tiny-shakespeare/train_coriolanus.csv.10percent"
train = "/home/shelbys/Datasets/tiny-shakespeare/train_coriolanus.csv.90percent"
#the_model = "tmp/train_coriolanus_e21_adamw_512-1024.nlp_best.pt"

[SAMPLE]
sample_model = "/home/shelbys/code/werernns/mingru/tmp/trn_corio_e7_gru90percent_256-1024.nlp_best.pt"
#sample_model = "tmp/train_coriolanus.nlp_best.pt"