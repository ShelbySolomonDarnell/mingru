[MAIN]
seqlen = 256
vocab_size = 50257
emb_size = 768
hidden_sizes = [512, 1024, 2048, 4096]
norm = True
dropout = 0.15
num_epochs = 10
batch_size = 64
lr = 1e-3
num_tokens = 256
arch_gru  = minGRU
arch_lstm = minLSTM
datasetA = tiny-shakespeare

[TRAIN]
the_data = "~/Datasets/tiny-shakespeare/train_coriolanus.csv"
the_model = "tmp/train.nlp_best.pt"

[SAMPLE]
sample_model = "tmp/train_coriolanus.nlp_best.pt"