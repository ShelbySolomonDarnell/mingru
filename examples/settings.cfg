[MAIN]
seqlen = 256
vocab_size = 50257
emb_size = 768
hidden_sizes = [512, 1024, 2048]
norm = True
dropout = 0.15
num_epochs = 7
batch_size = 64
lr = 1e-3
num_tokens = 256
arch = minGRU
arch_gru  = minGRU
arch_lstm = minLSTM
datasetA = tiny-shakespeare

[TRAIN]
the_data = "~/Datasets/tiny-shakespeare/train_coriolanus.csv.10percent"
#the_model = "tmp/train_coriolanus_e21_adamw_512-1024.nlp_best.pt"

[SAMPLE]
sample_model = "tmp/trn_corio_e7_gru90percent_256-1024.nlp_best.pt"
#sample_model = "tmp/train_coriolanus.nlp_best.pt"